{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import re\n",
    "import regex\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from chemdataextractor.doc import Paragraph\n",
    "from seqlbtoolkit.Data import txt_to_token_span, span_dict_to_list\n",
    "from seqlbtoolkit.Utils import remove_combining_marks, format_text\n",
    "from textspan import align_spans\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "random.seed(42)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "text = \"Miscibility in blends involving copolymers of styrene and acrylonitrile (SAN's) has been an interesting subject of diversified studies. Most notably, the miscibility of SAN with poly(methyl methacrylate) (PMMA) and with poly(ε-caprolactone) (PCL) has been widely reported since 1974. Miscibility in SAN with acrylic polymers other than PMMA has not been reported until lately (1991) when Kishore et al. and Mandal et al. independently and simultaneously reported miscibility of poly(phenyl acrylate) with SAN's (15−35 or 11.5−32 wt % AN, respectively). In many reported miscible binary blend systems whose constituents involve at least one copolymer, it has been commonly observed that miscibility occurs in a range of copolymer compositions. This phenomenon has been attributed to the so-called “copolymer effect” by some investigators. The “copolymer effect” suggests that mutual repulsion between the constituents (copolymer units) of the copolymer prevails over other interactions and that the repulsion in the copolymer leads to miscibility in the homopolymer−copolymer pair.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data_file = '../data/polymer_names/multimodal_annos.jsonl'\n",
    "with open(data_file, 'r', encoding='utf-8') as f:\n",
    "    json_ls = [json.loads(jline) for jline in f.readlines()]"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tokens_list = list()\n",
    "spans_list = list()\n",
    "\n",
    "for json_l in tqdm(json_ls):\n",
    "    ori_txt = json_l['text']\n",
    "    txt = format_text(ori_txt)\n",
    "    spans = json_l['spans']\n",
    "\n",
    "    unlabeled_spans = [(s['start'], s['end']) for s in spans]\n",
    "    aligned_spans = align_spans(unlabeled_spans, ori_txt, txt)\n",
    "    lbs_dict = dict()\n",
    "    for span, lb in zip(aligned_spans, spans):\n",
    "        assert len(span) >= 1\n",
    "        s = span[0][0]\n",
    "        e = span[-1][1]\n",
    "        lbs_dict[(s, e)] = lb['label']\n",
    "\n",
    "    doc = Paragraph(txt)    \n",
    "    for sent in doc.sentences:\n",
    "        tokens = [tk.text for tk in sent.tokens]\n",
    "        txt_spans = dict()\n",
    "        for (s, e), v in lbs_dict.items():\n",
    "            if sent.start <= s and e <= sent.end:\n",
    "                txt_spans[(s-sent.start, e-sent.start)] = v\n",
    "        tk_spans = txt_to_token_span(tokens, sent.text, txt_spans)\n",
    "\n",
    "        tokens_list.append(tokens)\n",
    "        spans_list.append(tk_spans)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 702/702 [00:07<00:00, 88.37it/s] \n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "f_tokens_list = list()\n",
    "f_spans_list = list()\n",
    "\n",
    "# only keep the POLYMER entities\n",
    "for tks, spans in zip(tokens_list, spans_list):\n",
    "    f_spans = dict()\n",
    "    for (s, e), v in spans.items():\n",
    "        if v == 'POLYMER':\n",
    "            f_spans[(s, e)] = v\n",
    "    if f_spans.values():\n",
    "        f_tokens_list.append(tks)\n",
    "        f_spans_list.append(f_spans)\n",
    "    elif random.random() < 0.15:\n",
    "        f_tokens_list.append(tks)\n",
    "        f_spans_list.append(f_spans)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "len(f_tokens_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2372"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "f_tokens_list[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Modification',\n",
       " 'of',\n",
       " 'sulfonated',\n",
       " 'poly(ether',\n",
       " 'ether',\n",
       " 'ketone',\n",
       " ')',\n",
       " '(',\n",
       " 'SPEEK',\n",
       " ')',\n",
       " 'membrane',\n",
       " 'was',\n",
       " 'attempted',\n",
       " 'by',\n",
       " 'blending',\n",
       " 'charged',\n",
       " 'surface',\n",
       " 'modifying',\n",
       " 'macromolecule',\n",
       " '(',\n",
       " 'cSMM',\n",
       " ')',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "f_spans_list[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{(3, 7): 'POLYMER', (8, 9): 'POLYMER'}"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "inst_ids = list(range(len(tokens_list)))\n",
    "random.shuffle(inst_ids)\n",
    "\n",
    "train_ids = inst_ids[:int(np.ceil(0.7 * len(inst_ids)))]\n",
    "valid_ids = inst_ids[int(np.ceil(0.7 * len(inst_ids))): int(np.ceil(0.85 * len(inst_ids)))]\n",
    "test_ids = inst_ids[int(np.ceil(0.85 * len(inst_ids))):]"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_list = list()\n",
    "for idx in train_ids:\n",
    "    train_list.append({'text': tokens_list[idx], 'label': span_dict_to_list(spans_list[idx])})\n",
    "train_dict = {idx: inst for idx, inst in enumerate(train_list)}\n",
    "\n",
    "valid_list = list()\n",
    "for idx in valid_ids:\n",
    "    valid_list.append({'text': tokens_list[idx], 'label': span_dict_to_list(spans_list[idx])})\n",
    "valid_dict = {idx: inst for idx, inst in enumerate(valid_list)}\n",
    "\n",
    "test_list = list()\n",
    "for idx in test_ids:\n",
    "    test_list.append({'text': tokens_list[idx], 'label': span_dict_to_list(spans_list[idx])})\n",
    "test_dict = {idx: inst for idx, inst in enumerate(test_list)}\n",
    "\n",
    "with open('../data/pet/train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('../data/pet/valid.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(valid_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('../data/pet/test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_dict, f, ensure_ascii=False, indent=2)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sent_lens = [len(tks) for tks in tokens_list]\n",
    "max_len = np.max(sent_lens)\n",
    "mean_len = np.mean(sent_lens)\n",
    "\n",
    "meta_info = {\n",
    "    'entity_types': ['pol_IUPAC', 'pol_traditional', 'pol_acronym'],\n",
    "    'train_size': len(train_ids),\n",
    "    'valid_size': len(valid_ids),\n",
    "    'test_size': len(test_ids),\n",
    "    'max_length': int(max_len),\n",
    "    'mean_length': float(mean_len),\n",
    "    'num_labels': 5\n",
    "}\n",
    "with open('../data/pet/meta.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(meta_info, f, ensure_ascii=False, indent=2)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "text = 'us to assign them to the repeating carrabiose 2,4′-disulfate of ι-carrageenan.'\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "tokenizer.tokenize(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['us',\n",
       " 'to',\n",
       " 'assign',\n",
       " 'them',\n",
       " 'to',\n",
       " 'the',\n",
       " 'repeating',\n",
       " 'carr',\n",
       " '##abi',\n",
       " '##ose',\n",
       " '2',\n",
       " ',',\n",
       " '4',\n",
       " '′',\n",
       " '-',\n",
       " 'di',\n",
       " '##sul',\n",
       " '##fat',\n",
       " '##e',\n",
       " 'of',\n",
       " 'ι',\n",
       " '-',\n",
       " 'carr',\n",
       " '##age',\n",
       " '##ena',\n",
       " '##n',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "len('sao')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "len('São')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "'^ssp^ssp'.split('^ssp')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '', '']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "txt = 'The number‐average molecular weight (Mn) and polydispersity ratio ­(Mw/Mn) were estimated on the basis of a polystyrene calibration.'\n",
    "new_txt = format_text(txt)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('py36': conda)"
  },
  "interpreter": {
   "hash": "4bfb672d4f861269a58eb1763c916f7cb8bbb1a00cd45419fbfb7fe524719a45"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}